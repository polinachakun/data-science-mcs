{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19195d2bb16e679",
   "metadata": {},
   "source": [
    "# Task 1 - Simple Linear Regression\n",
    "\n",
    "- a) Perform a simple linear regression on the `Auto.csv` dataset. Use `mpg` as the response variable and `horsepower` as the predictor variable.\n",
    "    - i) Is there a relationship between the predictor and the response?\n",
    "    - ii) How strong is the relationship between the predictor and the response?\n",
    "    - iii) Is the relationship between the predictor and the response positive or negative?\n",
    "    - iv) What is the predicted `mpg` associated with a `horsepower` of 98? What are the associated 95% confidence and prediction intervals?\n",
    "- b) Plot the response and the predictor. Display the least squares regression line.\n",
    "- c) Perform a multiple linear regression on the dataset. Use `mpg` as the response variable and both `horsepower` and `weight` as the predictor variables. Use `statsmodels` to solve this task (instead of doing it manually). Does this model perform better than the simple linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "id": "c40aae2023569979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T21:45:41.819616Z",
     "start_time": "2024-10-03T21:45:41.520602Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "auto_df = pd.read_csv('Auto.csv')\n",
    "\n",
    "auto_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      mpg  cylinders  displacement horsepower  weight  acceleration  year  \\\n",
       "0    18.0          8         307.0        130    3504          12.0    70   \n",
       "1    15.0          8         350.0        165    3693          11.5    70   \n",
       "2    18.0          8         318.0        150    3436          11.0    70   \n",
       "3    16.0          8         304.0        150    3433          12.0    70   \n",
       "4    17.0          8         302.0        140    3449          10.5    70   \n",
       "..    ...        ...           ...        ...     ...           ...   ...   \n",
       "392  27.0          4         140.0         86    2790          15.6    82   \n",
       "393  44.0          4          97.0         52    2130          24.6    82   \n",
       "394  32.0          4         135.0         84    2295          11.6    82   \n",
       "395  28.0          4         120.0         79    2625          18.6    82   \n",
       "396  31.0          4         119.0         82    2720          19.4    82   \n",
       "\n",
       "     origin                       name  \n",
       "0         1  chevrolet chevelle malibu  \n",
       "1         1          buick skylark 320  \n",
       "2         1         plymouth satellite  \n",
       "3         1              amc rebel sst  \n",
       "4         1                ford torino  \n",
       "..      ...                        ...  \n",
       "392       1            ford mustang gl  \n",
       "393       2                  vw pickup  \n",
       "394       1              dodge rampage  \n",
       "395       1                ford ranger  \n",
       "396       1                 chevy s-10  \n",
       "\n",
       "[397 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford mustang gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>vw pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>dodge rampage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford ranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>chevy s-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows Ã— 9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "f213dd1d9695cc02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T21:45:44.666559Z",
     "start_time": "2024-10-03T21:45:44.662322Z"
    }
   },
   "source": [
    "auto_df['horsepower'] = pd.to_numeric(auto_df['horsepower'], errors='coerce')\n",
    "auto_df = auto_df.dropna(subset=['horsepower'])"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "29ba5e21cd58837",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T21:45:46.687052Z",
     "start_time": "2024-10-03T21:45:46.543166Z"
    }
   },
   "source": [
    "import plotly.graph_objects as go\n",
    "import statsmodels.api as sm\n",
    "\n",
    "x = auto_df['horsepower']\n",
    "y = auto_df['mpg']\n",
    "\n",
    "X = sm.add_constant(x)\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=y, mode='markers', name='Data'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=predictions, mode='lines', name='Regression Line'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Regression Plot of Horsepower vs MPG\",\n",
    "    xaxis_title=\"Horsepower\",\n",
    "    yaxis_title=\"MPG\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mplotly\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgraph_objects\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mgo\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mstatsmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msm\u001B[39;00m\n\u001B[1;32m      4\u001B[0m x \u001B[38;5;241m=\u001B[39m auto_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhorsepower\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      5\u001B[0m y \u001B[38;5;241m=\u001B[39m auto_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmpg\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "2546c5b4d17eff56",
   "metadata": {},
   "source": [
    "i) Is there a relationship between the predictor and the response?"
   ]
  },
  {
   "cell_type": "code",
   "id": "1576e4579628977f",
   "metadata": {},
   "source": [
    "# let's check with the null hypothesis that there is no relationship between the predictor and the response\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = auto_df['horsepower']\n",
    "X = sm.add_constant(X)\n",
    "y = auto_df['mpg']\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f6a83b6ea00915b3",
   "metadata": {},
   "source": [
    "\n",
    "We could stop here, we have what we need to answer the question. Let's go over this table step-by-step, because it looks overwhelming at first.\n",
    "\n",
    "For question i) the rows `const` and `horsepower` are interesting:\n",
    "\n",
    "```\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const         39.9359      0.717     55.660      0.000      38.525      41.347\n",
    "horsepower    -0.1578      0.006    -24.489      0.000      -0.171      -0.145\n",
    "```\n",
    "\n",
    "\n",
    "In our case, what we are doing with our linear regression is to estimate the following equation:\n",
    "\n",
    "$$\n",
    "\\text{mpg} = \\beta_0 + \\beta_1 \\times \\text{horsepower} + \\epsilon\n",
    "$$\n",
    "\n",
    "That is to say, we are estimating a simplified version of the function of `mpg`, based on `horsepower`. We include the error term $\\epsilon$ because we know that our model will not be perfect - there could be some fluctuations in `mpg` that we cannot explain with `horsepower` alone.\n",
    "Possible reasons for this include (this list is not exhaustive!):\n",
    "- The tools used to measure `mpg` are not perfect (all tools have some margin of error)\n",
    "- There are other variables that influence `mpg` that we are not considering (such as the weight of the car - which is almost definitely a factor)\n",
    "- Some random fluctuations that we cannot explain (but this could get philosophical - maybe our physical understanding of the universe is incomplete and there are some factors that we cannot explain yet, so even with perfect tools and all variables considered, there might still be fluctuations)\n",
    "\n",
    "In our table above, `const` is $\\hat{\\beta_0}$ and `horsepower` is $\\hat{\\beta_1}$. `statsmodels` has solved the linear regression for us and found the best values for $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ (which estimate the actual $\\beta_0$ and $\\beta_1$). The values are:\n",
    "- $\\hat{\\beta_0} = 39.9359$\n",
    "- $\\hat{\\beta_1} = -0.1578$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c44aca12f7c0e2e",
   "metadata": {},
   "source": [
    "Let's calculate these values by hand!\n",
    "\n",
    "To estimate the coefficients:\n",
    "\n",
    "$$\n",
    "\\begin{flalign*}\n",
    "\\hat{\\beta_0} &= \\bar{y} - \\hat{\\beta_1} \\times \\bar{x} \\\\\n",
    "\\hat{\\beta_1} &= \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\n",
    "\\end{flalign*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6759aa67af1883a7",
   "metadata": {},
   "source": [
    "Let's calculate $\\bar{x}$ first.\n",
    "\n",
    "$$\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$$"
   ]
  },
  {
   "cell_type": "code",
   "id": "685cf6c7e799c457",
   "metadata": {},
   "source": [
    "mean_x = 1 / len(X) * sum(X['horsepower'])\n",
    "mean_x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2af49e5c812c35b8",
   "metadata": {},
   "source": [
    "Let's calculate $\\hat{\\beta_1}$ next. This is the slope of the regression line. It tells us how much `mpg` changes for a one-unit increase in `horsepower`."
   ]
  },
  {
   "cell_type": "code",
   "id": "2c5b3e5c193d7cc6",
   "metadata": {},
   "source": [
    "beta1 = sum((X['horsepower'] - mean_x) * (y - y.mean())) / sum((X['horsepower'] - mean_x) ** 2)\n",
    "beta1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c458340a7d3de088",
   "metadata": {},
   "source": [
    "And now $\\hat{\\beta_0}$ - this is the intercept of the regression line."
   ]
  },
  {
   "cell_type": "code",
   "id": "ef8fc68452f89113",
   "metadata": {},
   "source": [
    "beta0 = y.mean() - beta1 * mean_x\n",
    "beta0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "40bbc6c4e094190",
   "metadata": {},
   "source": [
    "Next, let's calculate $\\sigma$.\n",
    "\n",
    "**Note**: This is *not* the same as the standard deviation. What we need here is the standard error of the residuals. The formula is:\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{\\Sigma_{i=1}^n(y_i - \\hat{y}_i)^2}{n-2}} = \\sqrt{\\frac{\\Sigma_{i=1}^n \\left( y_i - \\left( \\hat{\\beta_0} + \\hat{\\beta_1} * x_i \\right) \\right)^2 }{n - 2}}$$\n",
    "\n",
    "You can find this in the lecture slides as well. It says there:\n",
    "\n",
    "$$\\sigma^2 = Var(\\epsilon)$$\n",
    "\n",
    "From this it follows that $\\sigma = \\sqrt{Var(\\epsilon)}$.\n",
    "\n",
    "Why do we have to do divide by $n-2$? This is because we have estimated two parameters: $\\beta_0$ and $\\beta_1$. This is called the degrees of freedom. The calculation of our two parameters $\\beta_0$ and $\\beta_1$ has used up two degrees of freedom. So we have $n-2$ degrees of freedom left for the residuals. \n",
    "\n",
    " Let's look at an example, we have a population of exactly 100 points, and we want to calculate the variance of this population. But we only have a sample size of 3 points! We can calculate the variance of this sample, but it will not be the same as the variance of the population. But if we repeat this process many times, and take the average of the sample variances, we will approach the true variance of the population."
   ]
  },
  {
   "cell_type": "code",
   "id": "9d54de47464f7b83",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "population = np.random.randint(0, 100, 100)\n",
    "\n",
    "true_variance = sum((population - population.mean()) ** 2) / 100\n",
    "\n",
    "# take a sample of 3 points\n",
    "sample = np.random.choice(population, 3)\n",
    "sample_mean = np.mean(sample)\n",
    "sample_variance = sum((sample - sample_mean) ** 2) / (3 - 1)\n",
    "\n",
    "true_variance, sample_variance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a13316ab0618c973",
   "metadata": {},
   "source": [
    "We see that this is not close. But that is because we have a small sample size. If we repeat this process, and take the average over many sample variances, we will approach the true variance.\n",
    "\n",
    "In this example below the naive way to calculate the variance would be to divide by the sample size. But you need to remember that the sample mean is not the true mean, but rather already an estimate. That means our sample mean is \"drawn\" towards the sample points. The deviations from the sample mean are therefore, **on average**, smaller than the deviations from the true mean. Once we know the sample mean, one of our points becomes fixed, it can not vary anymore. That means we have lost one degree of freedom. That is why we divide by $n-1$ and not by $n$."
   ]
  },
  {
   "cell_type": "code",
   "id": "d983cc946f8dfcb2",
   "metadata": {},
   "source": [
    "sample_variances = []\n",
    "sample_variances_wrong = []\n",
    "for _ in range(10_000):\n",
    "    sample = np.random.choice(population, 3)\n",
    "    sample_mean = np.mean(sample)\n",
    "    sample_variance = sum((sample - sample_mean) ** 2) / (3 - 1)\n",
    "    sample_variances.append(sample_variance)\n",
    "\n",
    "    # we do not divide by the degrees of freedom\n",
    "    sample_variance_wrong = sum((sample - sample_mean) ** 2) / 3\n",
    "    sample_variances_wrong.append(sample_variance_wrong)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c2ed7da42267dc1",
   "metadata": {},
   "source": [
    "cumulative_mean_diffs = []\n",
    "cumulative_mean_variance = 0\n",
    "\n",
    "cumulative_mean_diffs_wrong = []\n",
    "cumulative_mean_variance_wrong = 0\n",
    "for i in range(len(sample_variances)):\n",
    "    cumulative_mean_variance = np.mean(sample_variances[:i + 1])\n",
    "    difference = cumulative_mean_variance - true_variance\n",
    "    cumulative_mean_diffs.append(difference)\n",
    "\n",
    "    cumulative_mean_variance_wrong = np.mean(sample_variances_wrong[:i + 1])\n",
    "    difference_wrong = cumulative_mean_variance_wrong - true_variance\n",
    "    cumulative_mean_diffs_wrong.append(difference_wrong)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "216b09677788a0a3",
   "metadata": {},
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(len(cumulative_mean_diffs))),\n",
    "    y=cumulative_mean_diffs,\n",
    "    mode='lines',\n",
    "    name='Cumulative Mean Difference'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(len(cumulative_mean_diffs_wrong))),\n",
    "    y=cumulative_mean_diffs_wrong,\n",
    "    mode='lines',\n",
    "    name='Cumulative Mean Difference (Wrong)'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Convergence of Sample Variance to True Variance',\n",
    "    xaxis_title='Sample Number',\n",
    "    yaxis_title='Difference from True Variance',\n",
    "    yaxis=dict(tickformat=\".4f\"),\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "643eff9723571c6d",
   "metadata": {},
   "source": [
    "The same principle applies to the residual standard error. We have estimated two parameters ($\\hat{\\beta_0}$ and $\\hat{\\beta_1}$), so need to compensate for that in the denominator."
   ]
  },
  {
   "cell_type": "code",
   "id": "1c34a81b502a92c6",
   "metadata": {},
   "source": [
    "from math import sqrt\n",
    "\n",
    "residual_std_error = sqrt(sum((y - (beta0 + beta1 * X['horsepower'])) ** 2) / (len(X) - 2))\n",
    "residual_std_error"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3377fbd568eeb081",
   "metadata": {},
   "source": [
    "Let's also calculate the confidence intervals.\n",
    "\n",
    "From the lecture we know that:\n",
    "\n",
    "$$\n",
    "\\begin{flalign*}\n",
    "SE(\\hat{\\beta_0})^2 &= \\sigma^2 \\left[ \\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2} \\right] \\\\\n",
    "SE(\\hat{\\beta_1})^2 &= \\frac{\\sigma^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\n",
    "\\end{flalign*}\n",
    "$$\n",
    "\n",
    "\n",
    "Next, the standard error of $\\hat{\\beta_0}$."
   ]
  },
  {
   "cell_type": "code",
   "id": "271154295fd5b0d8",
   "metadata": {},
   "source": [
    "se_beta0 = residual_std_error * sqrt(1 / len(X) + mean_x ** 2 / sum((X['horsepower'] - mean_x) ** 2))\n",
    "se_beta0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "37a0d782972e59a6",
   "metadata": {},
   "source": [
    "And the standard error of $\\hat{\\beta_1}$."
   ]
  },
  {
   "cell_type": "code",
   "id": "1799688c604f21c7",
   "metadata": {},
   "source": [
    "se_beta1 = residual_std_error / sqrt(sum((X['horsepower'] - mean_x) ** 2))\n",
    "se_beta1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aeceed183e2bdead",
   "metadata": {},
   "source": [
    "Until here, we have calculated the following values:\n",
    "\n",
    "- $\\hat{\\beta_0} = 39.9359$\n",
    "- $\\hat{\\beta_1} = -0.1578$\n",
    "- $\\sigma = 4.90575691954594$\n",
    "- $SE(\\hat{\\beta_0}) = 0.7174986555545253$\n",
    "- $SE(\\hat{\\beta_1}) = 0.006445500517685023$"
   ]
  },
  {
   "cell_type": "code",
   "id": "a516855f098ea2d",
   "metadata": {},
   "source": [
    "beta0, beta1, residual_std_error, se_beta0, se_beta1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b74a53309c21b7ca",
   "metadata": {},
   "source": [
    "```\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const         39.9359      0.717     55.660      0.000      38.525      41.347\n",
    "horsepower    -0.1578      0.006    -24.489      0.000      -0.171      -0.145\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16b655e68ab01be",
   "metadata": {},
   "source": [
    "Now we can calculate the confidence intervals for $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$.\n",
    "\n",
    "The formula for the confidence interval of $\\hat{\\beta_0}$ is:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta_0} \\pm 2 \\times SE(\\hat{\\beta_0})\n",
    "$$\n",
    "\n",
    "And for $\\hat{\\beta_1}$:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta_1} \\pm 2 \\times SE(\\hat{\\beta_1})\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "6584004e337e3444",
   "metadata": {},
   "source": [
    "ci_beta0 = (beta0 - 2 * se_beta0, beta0 + 2 * se_beta0)\n",
    "ci_beta0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2c6bbe28b0b56d1f",
   "metadata": {},
   "source": [
    "ci_beta1 = (beta1 - 2 * se_beta1, beta1 + 2 * se_beta1)\n",
    "ci_beta1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7d48bccc5e8fc1d4",
   "metadata": {},
   "source": [
    "These values are very slightly different from the ones that `statsmodels` gives us (look at the CI for $\\beta_0$). This is because the value $2$ we used in the calculation of the confidence intervals is only an approximation. To replicate the values from `statsmodels` exactly, we need to use the t-distribution."
   ]
  },
  {
   "cell_type": "code",
   "id": "a323bba52639c945",
   "metadata": {},
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "degrees_of_freedom = len(X) - 2\n",
    "t_value = t.ppf(0.975, degrees_of_freedom)\n",
    "t_value"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "63e6881d44caaba",
   "metadata": {},
   "source": [
    "Let's plot the t-distribution for our case."
   ]
  },
  {
   "cell_type": "code",
   "id": "872c8c4fe63df09d",
   "metadata": {},
   "source": [
    "x = np.linspace(-4, 4, 1000)\n",
    "y_t_dist = t.pdf(x, degrees_of_freedom)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=y_t_dist, mode='lines', name='t-distribution'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=y_t_dist, fill='tozeroy',\n",
    "                         fillcolor='rgba(0,100,80,0.2)',\n",
    "                         line=dict(color='rgba(255,255,255,0)'),\n",
    "                         showlegend=False,\n",
    "                         hoverinfo=\"skip\"))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[t_value, t_value], y=[0, max(y_t_dist)], mode='lines',\n",
    "                         line=dict(color='red', dash='dash'),\n",
    "                         name=f'Critical t-value = {t_value:.2f}'))\n",
    "\n",
    "fig.update_layout(title=f'T-Distribution with {int(degrees_of_freedom)} Degrees of Freedom',\n",
    "                  xaxis_title='t-value',\n",
    "                  yaxis_title='Probability Density',\n",
    "                  showlegend=True)\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "24ab4b4c424128ea",
   "metadata": {},
   "source": [
    "The critical t-value tells us where 97.5% of our data lies. We use this for hypothesis testing, to see how likely it is that our data lies within a certain range. If we fall outside of this range (on the right side), then this is very unusual - because 97.5% of our data lies left of the critical t-value."
   ]
  },
  {
   "cell_type": "code",
   "id": "56a5bd432a10fc06",
   "metadata": {},
   "source": [
    "ci_beta0 = (beta0 - t_value * se_beta0, beta0 + t_value * se_beta0)\n",
    "ci_beta0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3997904a610b8c44",
   "metadata": {},
   "source": [
    "ci_beta1 = (beta1 - t_value * se_beta1, beta1 + t_value * se_beta1)\n",
    "ci_beta1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2f1117cc82e734b2",
   "metadata": {},
   "source": [
    "Let's compare them to the values from `statsmodels`:\n",
    "\n",
    "```\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const         39.9359      0.717     55.660      0.000      38.525      41.347\n",
    "horsepower    -0.1578      0.006    -24.489      0.000      -0.171      -0.145\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e078a8b12f3b120",
   "metadata": {},
   "source": [
    "Next is the `t` value in the `statsmodels` output. This is **not** the critical t-value, but rather the *t-statistic*. The t-statistic is calculated as:\n",
    "\n",
    "$$\n",
    "t = \\frac{\\hat{\\beta_1} - \\beta_1}{SE(\\hat{\\beta})}\n",
    "$$\n",
    "\n",
    "Now think all the way back to the beginning - what are we trying to do here?\n",
    "\n",
    "We want to test the null hypothesis that there is no relationship between `horsepower` and `mpg`. In other words, we want to test if $\\beta_1 = 0$. If this is the case, then our estimation for `mpg` becomes:\n",
    "\n",
    "$$\n",
    "\\text{mpg} = \\beta_0 + 0 * \\beta_1 + \\epsilon = \\beta_0 + \\epsilon\n",
    "$$\n",
    "\n",
    "So to calculate the t-statistic for $\\beta_1$, we use the formula:\n",
    "\n",
    "$$\n",
    "t = \\frac{\\hat{\\beta_1} - 0}{SE(\\hat{\\beta_1})}\n",
    "$$\n",
    "\n",
    "If it turns out that there **is** a relationship between `horsepower` and `mpg`, then we will reject the null hypothesis and accept the alternative hypothesis that $\\beta_1 \\neq 0$."
   ]
  },
  {
   "cell_type": "code",
   "id": "abed1a676b66b42b",
   "metadata": {},
   "source": [
    "t_statistic_beta1 = beta1 / se_beta1\n",
    "t_statistic_beta1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "49b3624396c08d81",
   "metadata": {},
   "source": [
    "t_statistic_beta0 = beta0 / se_beta0\n",
    "t_statistic_beta0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e9e15c530a99b7df",
   "metadata": {},
   "source": [
    "If the magnitude of the t-statistic is larger than the critical t-value, then we can reject the null hypothesis. This means that there is a relationship between the coefficient and `mpg`. This is used to calculate the p-value, which is the probability of observing a t-statistic as extreme as the one we have calculated, given that the null hypothesis is true."
   ]
  },
  {
   "cell_type": "code",
   "id": "ece25818d29d54ca",
   "metadata": {},
   "source": [
    "p_value_beta1 = 2 * (1 - t.cdf(np.abs(t_statistic_beta1), degrees_of_freedom))\n",
    "p_value_beta1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7b7afcdd86d9c4dd",
   "metadata": {},
   "source": [
    "p_value_beta0 = 2 * (1 - t.cdf(np.abs(t_statistic_beta0), degrees_of_freedom))\n",
    "p_value_beta0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "437c95ae5827b4ba",
   "metadata": {},
   "source": [
    "In this case we have $P>|t| = 0.000$ for both $\\beta_0$ and $\\beta_1$. This means that we can reject the null hypothesis that there is no relationship between the predictor variables (`horsepower` and the intercept) and `mpg`, as captured by $\\beta_0$ and $\\beta_1$. This leads us to accepting the alternative hypothesis that there is a relationship between the predictor variables and `mpg`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fab47a4e1dcc67",
   "metadata": {},
   "source": [
    "ii) How strong is the relationship between the predictor and the response?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90404a4819258ba4",
   "metadata": {},
   "source": [
    "In the lecture we have seen the Residual Standard Error. It is the average deviation of response values from the true regression line. Even if we knew $\\beta_0$ and $\\beta_1$ we would not be able to perfectly predict $Y$ from $X$.\n",
    "\n",
    "The formula for the RSE is:\n",
    "\n",
    "$$\n",
    "RSE = \\sqrt{\\frac{1}{n-2} RSS}\n",
    "$$\n",
    "\n",
    "And the RSS (Residual Sum of Squares) is calculated like so:\n",
    "\n",
    "$$\n",
    "RSS = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "id": "3af6d98a186cfa61",
   "metadata": {},
   "source": [
    "rss = sum((y - predictions) ** 2)\n",
    "rss"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "37e66f9fa20dbb43",
   "metadata": {},
   "source": [
    "rse = sqrt(rss / (len(X) - 2))\n",
    "rse"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6e69fdf1e92d0c81",
   "metadata": {},
   "source": [
    "The RSE is considered a measure of the *lack of fit* of the model to the data. So in our case, how well does our model fit the data?\n",
    "If our model is very good, then the model predictions will be very close to the true outcome values, in other words $\\hat{y_i} \\approx y_i$ then the RSE will be small. If the RSE is high, then that means that our predictions are not good, and this indicates that the model doesn't fit the data very well.\n",
    "\n",
    "Now as you can imagine the RSE does not have an upper limit. This makes it a bit difficult to interpret, because the values can get very large. That is why we use the $R^2$ value, which is a standardized measure of fit.\n",
    "\n",
    "The $R^2$ value is the proportion of variance explained by the model. It is calculated as:\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{RSS}{TSS}\n",
    "$$\n",
    "\n",
    "Where TSS is the Total Sum of Squares:\n",
    "\n",
    "$$\n",
    "TSS = \\sum_{i=1}^{n}(y_i - \\bar{y})^2\n",
    "$$\n",
    "\n",
    "The \"expanded\" form of the $R^2$ value is (writing it like this may make it a bit easier to remember or understand what's going on):\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^n\\left( y_i - \\hat{y_i} \\right)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "id": "84ea4c3d1742c26d",
   "metadata": {},
   "source": [
    "r2 = 1 - rss / sum((y - y.mean()) ** 2)\n",
    "r2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1dbab89cbf71e453",
   "metadata": {},
   "source": [
    "We can also get this value from the `statsmodels` summary from the table (top right corner), or programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "id": "3bd49b52de22e2c",
   "metadata": {},
   "source": [
    "model.rsquared"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b4ea5022a526af73",
   "metadata": {},
   "source": [
    "iii) Is the relationship between the predictor and the response positive or negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149e4d713c81dccb",
   "metadata": {},
   "source": [
    "The relationship between the predictor and the response is negative. This is because the coefficient for `horsepower` is negative. This means that if `horsepower` increases, then `mpg` decreases. This is a negative relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9b3560a9f32f99",
   "metadata": {},
   "source": [
    "iv) What is the predicted `mpg` associated with a `horsepower` of 98? What are the associated 95% confidence and prediction intervals?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d43c57d380b40b6",
   "metadata": {},
   "source": [
    "The predicted `mpg` associated with a `horsepower` of 98 is calculated as:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1} \\times x\n",
    "$$\n",
    "    \n",
    "Where $x = 98$."
   ]
  },
  {
   "cell_type": "code",
   "id": "a7551d4e7d668b17",
   "metadata": {},
   "source": [
    "task1_iv = beta0 + beta1 * 98\n",
    "task1_iv"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "af717701c1ee9ec8",
   "metadata": {},
   "source": [
    "To get the confidence and prediction intervals:"
   ]
  },
  {
   "cell_type": "code",
   "id": "f13043df21c2ef8e",
   "metadata": {},
   "source": [
    "se_pred_ci = residual_std_error * np.sqrt((1/len(X)) + ((98 - mean_x) ** 2 / sum((X['horsepower'] - mean_x) ** 2)))\n",
    "se_pred_ci"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cea6ecbfb441db2c",
   "metadata": {},
   "source": [
    "ci_task1_iv_lower = task1_iv - t_value * se_pred_ci\n",
    "ci_task1_iv_upper = task1_iv + t_value * se_pred_ci\n",
    "\n",
    "ci_task1_iv_lower, ci_task1_iv_upper"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f825f41e21538e1c",
   "metadata": {},
   "source": [
    "se_pred_pi = residual_std_error * np.sqrt(1 + (1/len(X)) + ((98 - mean_x) ** 2 / sum((X['horsepower'] - mean_x) ** 2)))\n",
    "pi_task1_iv_lower = task1_iv - t_value * se_pred_pi\n",
    "pi_task1_iv_upper = task1_iv + t_value * se_pred_pi\n",
    "\n",
    "pi_task1_iv_lower, pi_task1_iv_upper"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "107b68830f5d5f06",
   "metadata": {},
   "source": [
    "Or, taking them from `statsmodels` directly:"
   ]
  },
  {
   "cell_type": "code",
   "id": "523f49438991525a",
   "metadata": {},
   "source": [
    "model.get_prediction([1, 98]).summary_frame(alpha=0.05)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "be3bec98769682ea",
   "metadata": {},
   "source": [
    "b) Plot the response and the predictor. Display the least squares regression line."
   ]
  },
  {
   "cell_type": "code",
   "id": "da693d1330ce34d8",
   "metadata": {},
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=auto_df['horsepower'], y=auto_df['mpg'], mode='markers', name='Data'))\n",
    "\n",
    "predictions = model.predict(X)\n",
    "fig.add_trace(go.Scatter(x=X['horsepower'], y=predictions, mode='markers', name='Predictions'))\n",
    "\n",
    "# get regression line from model\n",
    "beta0 = model.params['const']\n",
    "beta1 = model.params['horsepower']\n",
    "\n",
    "x_line = np.linspace(auto_df['horsepower'].min(), auto_df['horsepower'].max(), 100)\n",
    "y_line = beta0 + beta1 * x_line\n",
    "fig.add_trace(go.Scatter(x=x_line, y=y_line, mode='lines', name='Regression Line'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Regression Plot of Horsepower vs MPG\",\n",
    "    xaxis_title=\"Horsepower\",\n",
    "    yaxis_title=\"MPG\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5fc372ffde12f1d6",
   "metadata": {},
   "source": [
    "c) Perform a multiple linear regression on the dataset. Use `mpg` as the response variable and both `horsepower` and `weight` as the predictor variables. Use `statsmodels` to solve this task (instead of doing it manually). Does this model perform better than the simple linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "id": "a4713ebac0ad2f62",
   "metadata": {},
   "source": [
    "X = auto_df[['horsepower', 'weight']]\n",
    "X = sm.add_constant(X)\n",
    "y = auto_df['mpg']\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7eb4cf46ca6318d",
   "metadata": {},
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(auto_df, x='horsepower', y='weight', z='mpg', opacity=0.5)\n",
    "fig.update_traces(marker=dict(size=5))\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis_title='Horsepower',\n",
    "    yaxis_title='Weight',\n",
    "    zaxis_title='MPG'\n",
    "))\n",
    "\n",
    "x_surf, y_surf = np.meshgrid(np.linspace(auto_df['horsepower'].min(), auto_df['horsepower'].max(), 100),\n",
    "                             np.linspace(auto_df['weight'].min(), auto_df['weight'].max(), 100))\n",
    "\n",
    "exog = pd.DataFrame({'const': np.ones(10000), 'horsepower': x_surf.ravel(), 'weight': y_surf.ravel()})\n",
    "out = model.predict(exog=exog)\n",
    "\n",
    "fig.add_trace(go.Surface(x=x_surf, y=y_surf, z=out.values.reshape(x_surf.shape), showscale=False))\n",
    "\n",
    "fig.update_layout(height=800)\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ad57d1acfba0c21f",
   "metadata": {},
   "source": [
    "# Task 2 - Pokemon Linear Regression\n",
    "\n",
    "- a) Perform a simple linear regression on the `pokemon.csv` dataset. Use `generation` as the response variable and `speed` as the predictor variable. Use `statsmodels` to solve this task.\n",
    "    - i) Is there a relationship between the predictor and the response?\n",
    "    - ii) How strong is the relationship between the predictor and the response?\n",
    "    - iii) Is the relationship between the predictor and the response positive or negative?\n",
    "- b) ðŸ’¬ Discuss in pairs: How can you improve the model or build a new, better model?"
   ]
  },
  {
   "cell_type": "code",
   "id": "d3950d2861f4fade",
   "metadata": {},
   "source": [
    "pokemon_df = pd.read_csv('pokemon.csv')\n",
    "pokemon_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b65b5ce2f1e9df2",
   "metadata": {},
   "source": [
    "x = pokemon_df[['speed']]\n",
    "X = sm.add_constant(x)\n",
    "y = pokemon_df['generation']\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a003746f111f6167",
   "metadata": {},
   "source": [
    "We see here that our p-value for the coefficient of `speed` is $0.574$. This means that we cannot reject the null hypothesis that there is no relationship between `speed` and `generation`. This means that we cannot say that there is a relationship between `speed` and `generation`.\n",
    "\n",
    "We can also see from the table that the $R^2$ is 0, which means that the model does not explain any of the variance in `generation`. This is another indicator that there is no relationship between `speed` and `generation`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aeb0ac51c7c1e6",
   "metadata": {},
   "source": [
    "b) How can you improve the model or build a new, better model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890bd92d61c36fd9",
   "metadata": {},
   "source": [
    "One way to improve the model is to use a different predictor variable. We can see from the table that the coefficient for `speed` is not significant. This means that `speed` is not a good predictor for `generation`. Let's see which variables are the best predictors for `generation`. We can do this by calculating the correlation between all variables and `generation`."
   ]
  },
  {
   "cell_type": "code",
   "id": "7bcad5bef03d39e4",
   "metadata": {},
   "source": [
    "pokemon_df[['attack', 'defense', 'sp_attack', 'sp_defense', 'hp', 'generation', 'speed']].corr()['generation']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a5d040e0a9cdd49e",
   "metadata": {},
   "source": [
    "From this analysis, it seems like `attack` and `hp` may be useful, due to their (comparatively) high correlation. Our original predictor, `speed`, has a slightly negative correlation with `generation`, which is why it is not a good predictor."
   ]
  },
  {
   "cell_type": "code",
   "id": "8271d0769ead44e6",
   "metadata": {},
   "source": [
    "x = pokemon_df[['attack', 'hp']]\n",
    "X = sm.add_constant(x)\n",
    "y = pokemon_df['generation']\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d87a62e1d2908dba",
   "metadata": {},
   "source": [
    "`hp` fails to be significant, but `attack` is significant. This means that `attack` is a good predictor for `generation`. Let's try a model with *only* this predictor."
   ]
  },
  {
   "cell_type": "code",
   "id": "5e60115d05c15c2",
   "metadata": {},
   "source": [
    "x = pokemon_df['attack']\n",
    "X = sm.add_constant(x)\n",
    "y = pokemon_df['generation']\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2c2a75fd53f25ce2",
   "metadata": {},
   "source": [
    "For the single-predictor model the $R^2$ decreased, compared to the one with two predictors. This may seem confusing, because the predictor we removed was not statistically significant (it failed the p-test). This is a problem with the $R^2$ metrics - it does not care whether the predictors are statistically significant. That's why the adjusted $R^2$ is often used. The adjusted $R^2$ is calculated as:\n",
    "\n",
    "$$\n",
    "R^2_{adj} = 1 - \\left( \\frac{\\left(1 - R^2\\right) \\times \\left(n - 1\\right)}{n - k - 1} \\right)\n",
    "$$\n",
    "\n",
    "Where $n$ is the number of observations and $k$ is the number of predictors. This metric penalizes the $R^2$ value for having too many predictors. We can see that in our case for both models this is (ignoring rounding) the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b373daf6716e81df",
   "metadata": {},
   "source": [
    "# Task 3 - Databases\n",
    "\n",
    "In this task we have access to the Spotify database (not really, but let's pretend it's the actual Spotify database - it's a dataset taken from [Kaggle](https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset)).\n",
    "\n",
    "The focus of this course is not on databases, but they are something you will encounter in Data Science projects. If you want to learn more about databases, there is a course called *Advanced Databases* that you can take!\n",
    "\n",
    "We will pretend like we know nothing about the database and will try to explore it.\n",
    "\n",
    "\n",
    "- a) Load the database into a DataFrame. You can use [`pd.read_sql`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql.html) to do this.\n",
    "- b) ðŸ’¬ Discuss in pairs: Do you notice any issues? If so, what are they?\n",
    "    - There are multiple things that could be improved in this DataFrame. Depending on what step(s) you would do next with this data you can ignore them, or you have to find ways to fix or work around them.\n",
    "    - In this scenario, we want to train a model that can detect if a text is explicit or not - we want to train a model on this data using the `explicit` and `track_name` columns. There is one main issue that we need to fix before we can do this.\n",
    "    - *Hint*: There is a cell provided that highlights the issue. Try to find it without using it first - in a real project checking for potential issues in your data is a step that you need to do without any help.\n",
    "- c) Fix the issue(s) you have found.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a0e61f606abbeee5",
   "metadata": {},
   "source": [
    "# the cell here may not display anything, depending on how you run the notebook - if it doesn't work you can ignore it\n",
    "# it should work if you open your jupyter notebook in a browser\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "spotify_embed_code = \"\"\"\n",
    "<iframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/track/3QeOoGlEnOfsgghQvsLenS?utm_source=generator&theme=0\" width=\"100%\" height=\"352\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"></iframe>\n",
    "\"\"\"\n",
    "display(HTML(spotify_embed_code))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b38f5bb06eba2af2",
   "metadata": {},
   "source": [
    "In our case the database is a very simple `sqlite` database. It's just one file - `database.db`. Normally databases are much more complex and consist of multiple files and sharing them is not as trivial as it is in our case."
   ]
  },
  {
   "cell_type": "code",
   "id": "2f9beb7b28b8d056",
   "metadata": {},
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('database.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "tables"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "860bc2569563269d",
   "metadata": {},
   "source": [
    "# get all column names\n",
    "cursor.execute(\"PRAGMA table_info(spotify)\")\n",
    "columns = cursor.fetchall()\n",
    "columns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c18643407b2ddcfd",
   "metadata": {},
   "source": [
    "Solution a):"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a901dfe3056f78d",
   "metadata": {},
   "source": [
    "spotify_df = pd.read_sql_query(\"SELECT * FROM spotify\", conn)\n",
    "spotify_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ff4f9d4e7c329c68",
   "metadata": {},
   "source": [
    "Task b) hint cell:"
   ]
  },
  {
   "cell_type": "code",
   "id": "cfd430fbb8832ae4",
   "metadata": {},
   "source": [
    "spotify_df[spotify_df['artists'] == 'Nightwish']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "18ba66c60045268e",
   "metadata": {},
   "source": "Solution b):"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "There are odd characters in the `track_name` column. Something went wrong. It looks like the data was saved incorrectly in the database.\n",
    "This can happen sometimes - it's an issue with encoding. Usually what we want is UTF-8 encoding. So for now let's try out various wrong encodings, and see which one works in our case, to find a way to fix the broken data."
   ],
   "id": "e8a4c8eb389cc2ae"
  },
  {
   "cell_type": "markdown",
   "id": "59081e1e5249b5d7",
   "metadata": {},
   "source": [
    "Solution c):"
   ]
  },
  {
   "cell_type": "code",
   "id": "e9460a1c6419a747",
   "metadata": {},
   "source": [
    "def fix_encoding(broken_text, wrong_encoding, correct_encoding='utf-8'):\n",
    "    try:\n",
    "        return broken_text.encode(wrong_encoding).decode(correct_encoding)\n",
    "    except UnicodeDecodeError:\n",
    "        return broken_text\n",
    "    except AttributeError:\n",
    "        return broken_text"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7438ae06ecbcb49b",
   "metadata": {},
   "source": [
    "import encodings\n",
    "import pkgutil\n",
    "\n",
    "available_encodings = set([modname for _, modname, _ in pkgutil.iter_modules(encodings.__path__)])\n",
    "available_encodings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f06dbba50ae549aa",
   "metadata": {},
   "source": [
    "broken_text = \"ÃƒÂ‰lan\"\n",
    "\n",
    "for enc in available_encodings:\n",
    "    try:\n",
    "        fixed_text = fix_encoding(broken_text, enc)\n",
    "        print(f\"Using encoding {enc}: {fixed_text}\")\n",
    "    except Exception as e:\n",
    "        # print(f\"Error using encoding {enc}: {e}\")\n",
    "        pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2ad93ed650467b87",
   "metadata": {},
   "source": [
    "Of these options, a bunch of them look like they could work. Let's try `iso8859_10` on the entire column."
   ]
  },
  {
   "cell_type": "code",
   "id": "377cec51201b5955",
   "metadata": {},
   "source": [
    "# spotify_df['track_name'].apply(fix_encoding, wrong_encoding='iso8859_10')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c8d80e81f790de4f",
   "metadata": {},
   "source": [
    "This didn't work - let's try `latin_1`."
   ]
  },
  {
   "cell_type": "code",
   "id": "6f1dbf98b5a30be5",
   "metadata": {},
   "source": [
    "spotify_df['track_name'].apply(fix_encoding, wrong_encoding='latin_1')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8d099bcaf9be0ae7",
   "metadata": {},
   "source": [
    "This worked! Now we can actually apply it to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "id": "12457d67a9892d55",
   "metadata": {},
   "source": [
    "spotify_df['track_name'] = spotify_df['track_name'].apply(fix_encoding, wrong_encoding='latin_1')\n",
    "spotify_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f015b2a79eeb910",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
